{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786c9df3-20bc-42d9-bb8c-2af8d9887ddd",
   "metadata": {},
   "source": [
    "# Gemma in the Hugging Face Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f6e2a-b444-4c8d-8162-59818cd18c5e",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/sanchit-gandhi/notebooks/blob/main/gemma_pipeline.jpg?raw=true\" width=\"800\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef752c-1a66-4240-bacf-c6432ab77354",
   "metadata": {
    "id": "bfef752c-1a66-4240-bacf-c6432ab77354"
   },
   "source": [
    "##Â Inference with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd3de1-e117-47ac-ab90-125d4c47dd15",
   "metadata": {
    "id": "20dd3de1-e117-47ac-ab90-125d4c47dd15"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\")\n",
    "\n",
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, do_sample=True, max_new_tokens=256)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598743a0-af5b-4b00-99d7-7b581e3b4023",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d322d-35df-474a-a4bf-465082b2f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7c20f-4250-4457-9f8e-e77f13b131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1ea52-eea0-4cc2-a442-00ffe347638e",
   "metadata": {},
   "source": [
    "## Training with TRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10445461-c956-4100-98a9-a67ce7910b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f98f6e-58d1-4f86-b788-110895a2cefe",
   "metadata": {},
   "source": [
    "Define training arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338b897-6018-4195-bb81-6c1dd0b202b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    output_dir=\"gemma-2b-fine-tuned\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b81fc-2e92-4bdb-a8af-e5a6e14cb399",
   "metadata": {},
   "source": [
    "Instantiate supervised fine-tuning (SFT) trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332abc97-4543-42c1-ba30-66c6dfa98aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307f0f5-afa2-4534-99c1-9ca2643de15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c45517-e543-496a-bca1-566a318c3d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
