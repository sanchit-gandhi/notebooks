{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/pipeline_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75bbdb5d-e4d5-4482-b4a4-9fcfbb5dc845",
      "metadata": {
        "id": "75bbdb5d-e4d5-4482-b4a4-9fcfbb5dc845"
      },
      "source": [
        "# Hugging Face ü§ó Transformers: A Gateway to Advanced ML Models\n",
        "\n",
        "by [Sanchit Gandhi](https://huggingface.co/sanchit-gandhi) for the MIT MFin programme."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a01f496-e177-4e0c-8447-39fee88f8d9a",
      "metadata": {
        "id": "6a01f496-e177-4e0c-8447-39fee88f8d9a"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Hugging Face [ü§ó Transformers](https://huggingface.co/docs/transformers/index) is an open-source library for state-of-the-art machine learning models.\n",
        "It provides a unified interface for over 230 Transformer-based models, making it trivial to apply the latest research to a range of different tasks.\n",
        "The library offers various levels of interaction granularity, from editing the low-level source code, through to high-level 1-line commands that take\n",
        "care of all the complexity under-the-hood, making it accessible for ML researchers, practitioners and hobbyists alike.\n",
        "\n",
        "Models in the Transformers library can be applied to:\n",
        "\n",
        "1. üìù **Text:** for tasks like text classification, information extraction, summarisation, and text generation, in over 100 languages.\n",
        "2. üñºÔ∏è **Images:** for tasks like image classification, object detection, and segmentation.\n",
        "3. üó£Ô∏è **Audio:** for tasks like speech recognition, audio classification, and speech synthesis.\n",
        "\n",
        "Transformer models can also perform tasks on several modalities combined, such as visual question answering, optical character recognition, and information extraction from scanned documents.\n",
        "\n",
        "No matter the task or modality at hand, ü§ó Transformers has a model that you can use easily and quickly!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62e980eb-4ac4-494e-8fc3-9f07dd552b44",
      "metadata": {
        "id": "62e980eb-4ac4-494e-8fc3-9f07dd552b44"
      },
      "source": [
        "## Focus of This Tutorial: NLP Applications with Transformers\n",
        "\n",
        "This tutorial concentrates on the initial phases of the machine learning pipeline in the context of NLP, specifically:\n",
        "1. **Identifying the task:** given a specific input-output pair, what is the best choice of task to solve our problem?\n",
        "2. **Applying a pre-trained model:** load a pre-trained model from the Hub and apply it to our problem.\n",
        "\n",
        "For detailed information on other steps in the machine learning pipeline, including dataset selection, model fine-tuning, evaluation, and deployment,\n",
        "refer to the Hugging Face [Documentation](https://huggingface.co/docs).\n",
        "\n",
        "The tutorial will cover three popular NLP tasks, particularly relevant in the financial sector:\n",
        "1. **Sentiment Analysis**: automatically tag text according to it's sentiment (e.g. positive, negative, neutral).\n",
        "2. **Named-Entity Recognition (NER):** identify and classify key financial entities in text, such as company names, stock tickers, and monetary values.\n",
        "2. **Summarisation:** efficiently summarise financial reports or news articles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fae7087-da25-4b3f-b741-f8ea800898f8",
      "metadata": {
        "id": "7fae7087-da25-4b3f-b741-f8ea800898f8"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f77368d8-b81a-4568-a50b-a13e15ea6212",
      "metadata": {
        "id": "f77368d8-b81a-4568-a50b-a13e15ea6212"
      },
      "source": [
        "Sentiment analysis is the automated process of tagging data according to its sentiment, such as positive, negative and neutral.\n",
        "Sentiment analysis allows companies to analyse data at scale, in order to detect insights and automate processes. For example,\n",
        "one might wish to analyse financial news, market reports, or social media posts to gauge investor sentiment or market trends.\n",
        "This information can then be used to assess the overall economic outlook or to update stock market predictions.\n",
        "\n",
        "In the following example, we'll use the [BERT model](https://huggingface.co/docs/transformers/model_doc/bert) to classify an\n",
        "input text. The overall workflow is as follows:\n",
        "1. **Pre-processing:** the input text is converted to word-piece tokens by action of the tokenizer\n",
        "2. **Modelling:** the tokens are fed through the BERT model to get a sequence of encoder representations, one for each word-piece token\n",
        "3. **Prediction:** a linear (\"dense\") transformation is applied to the special [CLS] token to give the probabilities of each class\n",
        "4. **Post-processing:** the final class label is declared as the one with the highest probability\n",
        "\n",
        "These four steps are summarised below, working from bottom to top:\n",
        "\n",
        "<img src=\"https://github.com/huggingface/workshops/blob/main/nlp-zurich/images/clf_arch.png?raw=1\" width=600>\n",
        "\n",
        "If you want to dive into any of these stages in more detail, we refer you to the blog post [The Illustrated BERT](http://jalammar.github.io/illustrated-bert/), as well as the\n",
        "original [BERT paper](https://arxiv.org/abs/1810.04805).\n",
        "\n",
        "Working on the highest-level with Transformers, the `pipeline()` class handles all four stages for us. We simply have to feed it our\n",
        "input text, and we are returned the final class label prediction:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/sanchit-gandhi/notebook-figures/resolve/main/mit-tutorial/pipeline.png?download=true\" width=600>\n",
        "\n",
        "Let's see this in action below! First, we'll import the `pipeline()` from the Transformers library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f665be53-1607-4789-bbbc-2fbfdf5fafdd",
      "metadata": {
        "id": "f665be53-1607-4789-bbbc-2fbfdf5fafdd",
        "outputId": "cdc3cc72-5141-42c8-f218-2cc17baab2bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sanchit/hf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-23 13:57:05.873696: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-23 13:57:05.873725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-23 13:57:05.873765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-23 13:57:06.611124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f85d74-44fa-42b5-b8a3-c5846bc4ca6c",
      "metadata": {
        "id": "f6f85d74-44fa-42b5-b8a3-c5846bc4ca6c"
      },
      "source": [
        "We can then load a model into the `pipeline()` class. For this example, we'll use the official [DistilBERT](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) checkpoint from the Hugging Face Hub. You can switch this for any [text classification model](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads) on the Hub by replacing the model id:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f98833f-50d4-411f-bb96-84bd7f87b99d",
      "metadata": {
        "id": "2f98833f-50d4-411f-bb96-84bd7f87b99d"
      },
      "outputs": [],
      "source": [
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8958ed3a-ffdc-4426-a0ea-49163bce85fc",
      "metadata": {
        "id": "8958ed3a-ffdc-4426-a0ea-49163bce85fc"
      },
      "source": [
        "Let's define the text we want to classify. In this example, we'll use a summary of [Apple's Q3 Earnings Report](https://www.apple.com/uk/newsroom/2023/08/apple-reports-third-quarter-results/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2ec861-1e37-48eb-902b-f2979f47e564",
      "metadata": {
        "id": "0a2ec861-1e37-48eb-902b-f2979f47e564"
      },
      "outputs": [],
      "source": [
        "APPLE_EARNINGS = (\n",
        "    \"Apple today announced financial results for its fiscal 2023 third quarter ended July 1, 2023. The Company posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26, up 5 percent year over year. \"\n",
        "    \"'We are happy to report that we had an all-time revenue record in Services during the June quarter, driven by over 1 billion paid subscriptions, and we saw continued strength in emerging markets thanks to robust sales of iPhone,' said Tim Cook, Apple‚Äôs CEO. 'From education to the environment, we are continuing to advance our values, while championing innovation that enriches the lives of our customers and leaves the world better than we found it.'\"\n",
        "    \"'Our June quarter year-over-year business performance improved from the March quarter, and our installed base of active devices reached an all-time high in every geographic segment,' said Luca Maestri, Apple‚Äôs CFO. 'During the quarter, we generated very strong operating cash flow of $26 billion, returned over $24 billion to our shareholders, and continued to invest in our long-term growth plans.\"\n",
        "    \"Apple‚Äôs board of directors has declared a cash dividend of $0.24 per share of the Company‚Äôs common stock. The dividend is payable on August 17, 2023 to shareholders of record as of the close of business on August 14, 2023.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d702937-224d-48df-a6e4-54dfd1230c61",
      "metadata": {
        "id": "7d702937-224d-48df-a6e4-54dfd1230c61"
      },
      "source": [
        "Alright! We can now pass the text to the `pipeline()` and classify it accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1075e9c7-cce0-43e4-a92d-e215678af98c",
      "metadata": {
        "id": "1075e9c7-cce0-43e4-a92d-e215678af98c",
        "outputId": "ad0b9414-7647-42a6-f01f-fa91978362e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9991182684898376}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_prediction = sentiment_pipeline(APPLE_EARNINGS)\n",
        "sentiment_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce0b96a-72e5-473b-a2e8-290258e21cb7",
      "metadata": {
        "id": "7ce0b96a-72e5-473b-a2e8-290258e21cb7"
      },
      "source": [
        "Great - we see that the sentiment is \"positive\" with 99.9% probability. If you took the time to read through the earnings summary, you'd agree that this makes sense given the strong growth in revenue from services and subscriptions. You can see how such a system could be integrated into a financial workflow to make informed decisions based-on the information published in the news.\n",
        "\n",
        "In this example, we classified the *overall* sentiment of the text. That is, we predicted a single class label for the entire text. Let's now go a level deeper and make predictions on the *token-level*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d32e9ae-992a-46df-9cd6-249e59a51ea4",
      "metadata": {
        "id": "1d32e9ae-992a-46df-9cd6-249e59a51ea4"
      },
      "source": [
        "##¬†Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77008213-c558-49b8-99bd-5cac85e7a7b4",
      "metadata": {
        "id": "77008213-c558-49b8-99bd-5cac85e7a7b4"
      },
      "source": [
        "Named entity recognition (NER) is the process of extracting **entities** from a passage of text. It can be used to identify and categorise financial entities such as company names, stock symbols, monetary values, and economic indicators from financial reports, news articles, or social media content. Therefore, it can be used to give a structured understanding of vast amounts of textual data.\n",
        "\n",
        "The workflow for NER is largely the same as sentiment analysis. However, instead of predicting the class probabilities for a single token, we\n",
        "predict probabilities for every token using the linear layer:\n",
        "\n",
        "<img src=\"https://github.com/huggingface/workshops/blob/main/nlp-zurich/images/ner_arch.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d883d80f-fc43-48cf-afcc-10ea8ca0ca30",
      "metadata": {
        "id": "d883d80f-fc43-48cf-afcc-10ea8ca0ca30"
      },
      "source": [
        "We can instantiate our NER pipeline in much the same way as our sentiment analysis one. This time, we'll use the checkpoint [dslim/bert-large-NER](https://huggingface.co/dslim/bert-large-NER):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb79ea8f-2429-4b49-9f12-84e7bf169113",
      "metadata": {
        "id": "bb79ea8f-2429-4b49-9f12-84e7bf169113",
        "outputId": "782493f2-0223-4833-f727-74a2b8bece5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-large-NER\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a7e425-5ee5-417b-83f2-f79789b89a40",
      "metadata": {
        "id": "09a7e425-5ee5-417b-83f2-f79789b89a40"
      },
      "source": [
        "Let's pass our earnings report to the NER pipeline to get our class predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c0ce37-9c57-4a31-af90-9966e223333a",
      "metadata": {
        "id": "98c0ce37-9c57-4a31-af90-9966e223333a",
        "outputId": "659705d7-4119-488d-b4af-23464fa50165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'entity_group': 'ORG', 'score': 0.99825484, 'word': 'Apple', 'start': 0, 'end': 5}, {'entity_group': 'MISC', 'score': 0.9887601, 'word': 'iPhone', 'start': 481, 'end': 487}, {'entity_group': 'PER', 'score': 0.99950564, 'word': 'Tim Cook', 'start': 495, 'end': 503}, {'entity_group': 'ORG', 'score': 0.9981773, 'word': 'Apple', 'start': 505, 'end': 510}, {'entity_group': 'PER', 'score': 0.98965263, 'word': 'Luca Maestri', 'start': 899, 'end': 911}, {'entity_group': 'ORG', 'score': 0.998454, 'word': 'Apple', 'start': 913, 'end': 918}, {'entity_group': 'ORG', 'score': 0.9986727, 'word': 'Apple', 'start': 1109, 'end': 1114}, {'entity_group': 'ORG', 'score': 0.56803095, 'word': 'Company', 'start': 1191, 'end': 1198}]\n"
          ]
        }
      ],
      "source": [
        "entities = ner_pipeline(APPLE_EARNINGS, aggregation_strategy=\"simple\")\n",
        "print(entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e48d0383-0ed2-4fd2-ab07-beba60f0b56f",
      "metadata": {
        "id": "e48d0383-0ed2-4fd2-ab07-beba60f0b56f"
      },
      "source": [
        "This isn't very easy to read, so let's clean up the outputs a bit by printing them on separate lines and rounding the class probabilities to 2 decimal places:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdd0268-8912-4f8b-a9c2-64f5081f62eb",
      "metadata": {
        "id": "afdd0268-8912-4f8b-a9c2-64f5081f62eb",
        "outputId": "ca72e055-02bb-4525-f86b-2279134e888a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple: ORG (1.00)\n",
            "iPhone: MISC (0.99)\n",
            "Tim Cook: PER (1.00)\n",
            "Apple: ORG (1.00)\n",
            "Luca Maestri: PER (0.99)\n",
            "Apple: ORG (1.00)\n",
            "Apple: ORG (1.00)\n",
            "Company: ORG (0.57)\n"
          ]
        }
      ],
      "source": [
        "for entity in entities:\n",
        "    print(f\"{entity['word']}: {entity['entity_group']} ({entity['score']:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4b91c6-2caf-4d0d-9e92-f5cab2917213",
      "metadata": {
        "id": "af4b91c6-2caf-4d0d-9e92-f5cab2917213"
      },
      "source": [
        "That's much better! It seems that the model found most of the named entities in the text: \"Apple\" is correctly identified as an organisation (ORG),\n",
        "and \"Tim Cook\" as a person (PER). The model also assigned the \"miscellaneous\" (MISC) label to \"iPhone\", indicating that it predicted it to be an\n",
        "important object in the text. If we want to refine the model for a specific domais, such as tech company earnings reports, we'd likely want to [fine-tune](https://huggingface.co/learn/nlp-course/chapter7/2) it on additional data, in order to give more detailed class labels and improve the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "411f12f7-5070-4883-aa6d-353f16139cfa",
      "metadata": {
        "id": "411f12f7-5070-4883-aa6d-353f16139cfa"
      },
      "source": [
        "## Why use the `pipeline()`?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773589be-c6d1-4574-aaa2-77e8df03d0aa",
      "metadata": {
        "id": "773589be-c6d1-4574-aaa2-77e8df03d0aa"
      },
      "source": [
        "When working on solving your own task, starting with a simple pipeline like the one shown above is a valuable tool that offers several benefits:\n",
        "\n",
        "* A pre-trained model may exist that already solves your task, saving you plenty of time\n",
        "* `pipeline()` takes care of all the pre/post-processing for you, so you don‚Äôt have to worry about getting the data into the right format for a model\n",
        "* If the result isn‚Äôt ideal, it gives you a baseline for future fine-tuning\n",
        "* Should you fine-tune a model on your custom data and share it on Hub, the whole community will be able to use it quickly and effortlessly via the `pipeline()` class, making AI more accessible\n",
        "\n",
        "In the NER task, we predicted a single class label for each of our token inputs. For our final task, we'll provide a text input, but predict a text output\n",
        "that can take variable length. We'll also expose a lower-level way of interacting with Transformers that explains how the `pipeline()` works under-the-hood."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1f4bf36-97da-4012-bae1-c1dde55403fc",
      "metadata": {
        "id": "a1f4bf36-97da-4012-bae1-c1dde55403fc"
      },
      "source": [
        "## Summarisation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e8fe41-7223-44ec-9c1e-74363a237655",
      "metadata": {
        "id": "46e8fe41-7223-44ec-9c1e-74363a237655"
      },
      "source": [
        "Summarsation creates a shorter version of a document or an article that captures all the important information. It can be used to distill lengthy financial statements and news articles into concise summaries that can be used to provide high-level overviews of the information conveyed.\n",
        "\n",
        "Summarisation is an example of a **sequence-to-sequence** task: a *sequence* of text inputs are mapped to a *sequence* of text outputs. The lengths of the outputs are not known beforehand, but are rather a function of the length of the inputs. Let's suppose we're summarising a one-line headline. At most, the summary will be one-line, since it cannot exceed the length of the input. However, a multi-page document will likely require a full paragraph to summarise all the information. The length of the output is not just a function of the input, but also the content of the text. For example, a very lengthy passage could be summarised in just one sentence, should there be little important information in the text. Whereas, an information-dense document of the same length may require multiple sentences.\n",
        "\n",
        "Summarisation can take one of two flavours:\n",
        "\n",
        "1. Extractive: extract the most relevant information from a document.\n",
        "2. Abstractive: generate new text that captures the most relevant information.\n",
        "\n",
        "In this example, we'll use an **abstractive** summarisation model to pull-out the key information from the earnings summary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3204933c-bd21-4af7-93e9-b9a03bec1419",
      "metadata": {
        "id": "3204933c-bd21-4af7-93e9-b9a03bec1419"
      },
      "source": [
        "You'll be very familiar with the pipeline workflow now! Let's go ahead and load one of the official [DistilBART](sshleifer/distilbart-cnn-12-6) checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33040e3f-98b8-4997-9362-fc714a63c023",
      "metadata": {
        "id": "33040e3f-98b8-4997-9362-fc714a63c023"
      },
      "outputs": [],
      "source": [
        "summarization_pipeline = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4bc82b-aaf2-4c20-93bd-60e12a2a2b01",
      "metadata": {
        "id": "6c4bc82b-aaf2-4c20-93bd-60e12a2a2b01"
      },
      "source": [
        "> **Tip:** a model with \"distil\" in the name likely means it is a compressed version of a larger model. These models tend to be smaller and faster to run, while largely maintaining the performance of the original model. Hugging Face has a big soft spot for distilling models, given they assist in making them more accessible to the community ü§ó. If you're interested in finding out more about model distillation, refer to the [DistilBERT](https://arxiv.org/abs/1910.01108), [DistilBART](https://arxiv.org/abs/2010.13002) and [Distil-Whisper](https://arxiv.org/abs/2311.00430) papers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40eef579-10cb-4c14-95b3-ca1537baea1c",
      "metadata": {
        "id": "40eef579-10cb-4c14-95b3-ca1537baea1c"
      },
      "source": [
        "As before, we'll pass the input text to the pipeline to get our outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d519df-89b7-4648-b3db-047d53e62eec",
      "metadata": {
        "id": "31d519df-89b7-4648-b3db-047d53e62eec",
        "outputId": "2553c085-e4b8-42a8-9591-c12d2ee12391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': \" Apple today announced financial results for its fiscal 2023 third quarter ended July 1, 2023 . The Company posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26 . 'We are happy to report that we had an all-time revenue record in Services during the June quarter'\"}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarization_pipeline(APPLE_EARNINGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a4abbf-b067-4011-8546-d4c9f0c6ef71",
      "metadata": {
        "id": "82a4abbf-b067-4011-8546-d4c9f0c6ef71"
      },
      "source": [
        "Fantastic - the model summarised the multi-paragraph input text into a one-paragraph summary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32397b91-f8b7-43db-a375-73f2919d4cda",
      "metadata": {
        "id": "32397b91-f8b7-43db-a375-73f2919d4cda"
      },
      "source": [
        "We can also string together all of our pipelines to:\n",
        "1. Generate a summary\n",
        "2. Predict the overall sentiment\n",
        "3. Classify the named entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2fdf3f8-904c-4a09-ad48-3fd78cce175c",
      "metadata": {
        "id": "e2fdf3f8-904c-4a09-ad48-3fd78cce175c",
        "outputId": "85685f78-e576-4d4d-cec9-174a1c82288f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Apple today announced financial results for its fiscal 2023 third quarter ended July 1, 2023 . The Company posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26 . 'We are happy to report that we had an all-time revenue record in Services during the June quarter'\n",
            "Sentiment:  {'label': 'POSITIVE', 'score': 0.9983645081520081}\n",
            "Entity: Apple ORG (1.00)\n"
          ]
        }
      ],
      "source": [
        "summary = summarization_pipeline(APPLE_EARNINGS)[0][\"summary_text\"]\n",
        "sentiment = sentiment_pipeline(summary)\n",
        "entities = ner_pipeline(summary, aggregation_strategy=\"simple\")\n",
        "\n",
        "print(summary)\n",
        "print(\"Sentiment: \", sentiment[0])\n",
        "\n",
        "for entity in entities:\n",
        "    print(f\"Entity: {entity['word']} {entity['entity_group']} ({entity['score']:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b949e6d9-f4af-41cb-80bc-4d4d9abf0dc4",
      "metadata": {
        "id": "b949e6d9-f4af-41cb-80bc-4d4d9abf0dc4"
      },
      "source": [
        "## Let's Go Deeper!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bac59b8-18a9-46c0-92ab-899ce7416e24",
      "metadata": {
        "id": "9bac59b8-18a9-46c0-92ab-899ce7416e24"
      },
      "source": [
        "So far, we've been using the `pipeline()` class, which takes care of the pre-processing, post-processing and modelling steps. In our final example, we'll use a lower-level API in Transformers, which splits these three steps up:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/sanchit-gandhi/notebook-figures/resolve/main/mit-tutorial/model_tokenizer.png?download=true\" width=600>\n",
        "\n",
        "To achieve this, we'll define two classes:\n",
        "1. The `tokenizer`: responsible for pre-processing the input text to token ids, and post-processing the predicted ids to output text\n",
        "2. The `model`: responsible for the auto-regressive generation\n",
        "\n",
        "We can go ahead and load the corresponding classes from the Transformers library. The first of these classes, `AutoTokenizer`, is the tokenizer class,\n",
        "which converts the input string to a token id (discrete number) representation. The second class, `AutoModelForSeq2SeqLM`, is our\n",
        "model class. This is the Python class that holds the model weights and graph definition:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf41f99-4be9-48ad-8d5e-8ba6b306b901",
      "metadata": {
        "id": "daf41f99-4be9-48ad-8d5e-8ba6b306b901"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "489b4cf3-3a19-4c89-bffb-a489c2fd53f1",
      "metadata": {
        "id": "489b4cf3-3a19-4c89-bffb-a489c2fd53f1"
      },
      "source": [
        "> **Tip:** using auto-classes means that we can easily swap the checkpoint id for any other checkpoint on the Hugging Face Hub and re-use our code without any changes. The auto-classes will take care of loading the correct model and tokenizer classes for us!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a4377ca-c1ff-4e13-9e60-61720424c66b",
      "metadata": {
        "id": "7a4377ca-c1ff-4e13-9e60-61720424c66b"
      },
      "source": [
        "Great! We can now load the model and tokenizer from the pre-trained checkpoint on the Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a1df6de-34e9-4b12-88f4-b5f2a23e2522",
      "metadata": {
        "id": "0a1df6de-34e9-4b12-88f4-b5f2a23e2522"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bcf657-62c2-408f-89a3-cc376350cb5a",
      "metadata": {
        "id": "e9bcf657-62c2-408f-89a3-cc376350cb5a"
      },
      "source": [
        "The model is now loaded into memory and ready to be used for predictions. Let's go through the steps for summarisation one-by-one.\n",
        "\n",
        "**Step 1:** pre-process (encode) the text inputs to token ids using the tokenizer. We'll return the input ids as PyTorch (pt) tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc98086-f61d-4140-80f7-71ddf0bf39a8",
      "metadata": {
        "id": "4bc98086-f61d-4140-80f7-71ddf0bf39a8",
        "outputId": "02eef746-8e7e-4f7f-cade-178b35e5105d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(APPLE_EARNINGS, max_length=2048, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e87bee-b1eb-413c-a985-5c5d1dddb49f",
      "metadata": {
        "id": "b1e87bee-b1eb-413c-a985-5c5d1dddb49f"
      },
      "source": [
        "**Step 2:** auto-regressively generate using the model to get the predicted ids. For this, we'll use the model's [`.generate`](https://huggingface.co/docs/transformers/main_classes/text_generation) method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a3a83b-0917-4fe4-9d56-8f8ab3c0da5f",
      "metadata": {
        "id": "37a3a83b-0917-4fe4-9d56-8f8ab3c0da5f"
      },
      "outputs": [],
      "source": [
        "pred_ids = model.generate(inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a2c0d9-c89a-4b33-b843-50c8942646a3",
      "metadata": {
        "id": "c5a2c0d9-c89a-4b33-b843-50c8942646a3"
      },
      "source": [
        "**Step 3:** post-process (decode) the predicted ids to the text outputs. We'll skip any \"special\" task token ids from the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a2a51f-f5bb-4137-bcd4-5d136b3a1ed9",
      "metadata": {
        "id": "52a2a51f-f5bb-4137-bcd4-5d136b3a1ed9",
        "outputId": "7f142f70-c0ac-4e1e-b79a-73933399be08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Apple announced financial results for its fiscal 2023 third quarter ended July 1, 2023. Company posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26. 'We are happy to report that we had an all-time revenue record in Services during the June quarter'\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(pred_ids[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59d29a9-8751-4ffc-a2b7-d81f7cce653d",
      "metadata": {
        "id": "d59d29a9-8751-4ffc-a2b7-d81f7cce653d"
      },
      "source": [
        "Alright! We see that we get the same output as we had using the `pipeline()`, but this time explicitly executing each step in the process. The following code-snippet concatenates the three so that they can be run one after the other, as you would typically have in any application:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3438d69-95b3-4c65-ae90-74c8627a23e4",
      "metadata": {
        "id": "c3438d69-95b3-4c65-ae90-74c8627a23e4",
        "outputId": "8c40e823-5904-4197-a48b-68c026a1a552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Apple announced financial results for its fiscal 2023 third quarter ended July 1, 2023. Company posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26. 'We are happy to report that we had an all-time revenue record in Services during the June quarter'\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(APPLE_EARNINGS, max_length=2048, return_tensors=\"pt\")\n",
        "\n",
        "pred_ids = model.generate(inputs[\"input_ids\"])\n",
        "\n",
        "pred_text = tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
        "print(pred_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ff893a-70c7-4786-bfd8-aca262956dd8",
      "metadata": {
        "id": "b2ff893a-70c7-4786-bfd8-aca262956dd8"
      },
      "source": [
        "## Why Go Deeper?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155b257a-4fc1-4110-9df3-dcacf88d3791",
      "metadata": {
        "id": "155b257a-4fc1-4110-9df3-dcacf88d3791"
      },
      "source": [
        "The advantage of using the lower-level `model` + `processor` API is that you have more control over the specific generation parameters. For example, we can enable the [*beam search*](https://huggingface.co/blog/how-to-generate#beam-search) and [*sampling*](https://huggingface.co/blog/how-to-generate#sampling) generation strategies by passing `num_beams=5` and `do_sample=True` respectively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886e4b15-463d-49de-8bdd-036d9d0034d9",
      "metadata": {
        "id": "886e4b15-463d-49de-8bdd-036d9d0034d9",
        "outputId": "2498bd5c-6ea2-4202-ec0e-c8fab09b2f59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\" Apple posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26. 'We are happy to report that we had an all-time revenue record in Services during the June quarter, driven by over 1 billion paid subscriptions'\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_ids = model.generate(inputs[\"input_ids\"], num_beams=5, do_sample=True)\n",
        "\n",
        "tokenizer.decode(pred_ids[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8298623d-9dfb-4787-b477-2c56ad9c7011",
      "metadata": {
        "id": "8298623d-9dfb-4787-b477-2c56ad9c7011"
      },
      "source": [
        "You also have access to the intermediate outputs in the workflow, for example the token ids from the tokenizer, or the predicted ids from the model. You can re-use these to quickly experiment with using different strategies without having to run everything from scratch each time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eccb2d26-9571-4e84-ab49-9640edcbdb82",
      "metadata": {
        "id": "eccb2d26-9571-4e84-ab49-9640edcbdb82"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff86807c-0993-4189-a4dc-1018987b2d9e",
      "metadata": {
        "id": "ff86807c-0993-4189-a4dc-1018987b2d9e"
      },
      "source": [
        "In this tutorial, we covered how the Transformers library can be applied to three common NLP tasks: sentiment analysis, NER and summarisation. We demonstrated the flexibility fo the `pipeline()` class for easily switching between different tasks, and the lower-level API for more fine-grained control over the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fcbab45-c25b-4189-80d4-cadc831c7d00",
      "metadata": {
        "id": "2fcbab45-c25b-4189-80d4-cadc831c7d00"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}